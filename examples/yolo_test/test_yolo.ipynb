{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gdown\n",
    "\n",
    "# import gdown\n",
    "# url_data = 'https://drive.google.com/file/d/1uqvV0_u3LbU-sDn0-epFH6NiWr4_uK4c/view?usp=share_link'\n",
    "# gdown.download(url=url_data, output=\"data.zip\", quiet=False, fuzzy=True)\n",
    "\n",
    "# import zipfile\n",
    "# with zipfile.ZipFile('data.zip', 'r') as zip_ref:\n",
    "#     zip_ref.extractall('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['README.roboflow.txt',\n",
       " 'valid',\n",
       " 'README.dataset.txt',\n",
       " 'test',\n",
       " 'data.yaml',\n",
       " 'train']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir('data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yolov5.train import train\n",
    "from yolov5.detect import run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python yolov5/train.py --img 256 --batch 16 --epochs 5 --data data/data.yaml --weights yolov5s.pt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import typing as tp\n",
    "import tempfile\n",
    "\n",
    "\n",
    "def removesuffix(line, suffixes):\n",
    "    for suffix in suffixes:\n",
    "        if line.endswith(suffix):\n",
    "            return line[:-len(suffix)]\n",
    "        \n",
    "\n",
    "class YoloWrapper():\n",
    "    def __init__(self, weights,\n",
    "                 data_yaml='data/data.yaml',\n",
    "                 img_size=(256, 256),\n",
    "                 save_txt=True,\n",
    "                 project='preds',\n",
    "                 exist_ok=False,\n",
    "                 name='') -> None:\n",
    "        self.weights = weights\n",
    "        self.data_yaml = data_yaml\n",
    "        self.img_size = img_size\n",
    "        self.save_txt = save_txt\n",
    "        self.project = project\n",
    "        self.exist_ok = exist_ok\n",
    "        self.name = name\n",
    "        \n",
    "    @staticmethod\n",
    "    def dct_preds(line):\n",
    "        splited_line = line.strip().split()\n",
    "        res = {'class_id':splited_line[0],\n",
    "                'center_x': float(splited_line[1]),\n",
    "                'center_y': float(splited_line[2]),\n",
    "                'width': float(splited_line[3]),\n",
    "                'height': float(splited_line[4])}\n",
    "        if len(splited_line) == 6:\n",
    "            res.update({'conf': float(splited_line[5])})\n",
    "        return res\n",
    "        \n",
    "    def _predict(self, source, data, imgsz, save_path):\n",
    "        shutil.rmtree(save_path)\n",
    "        run(weights=self.weights, source=source, data=data,\n",
    "            imgsz=imgsz, save_txt=True, project='preds',\n",
    "            exist_ok=False, name='', save_conf=True)\n",
    "        \n",
    "    def predict(self, X: tp.List[str]):\n",
    "        with tempfile.NamedTemporaryFile(mode='w', suffix='.txt') as fp:\n",
    "            fp.write(\"\\n\".join(X))\n",
    "            fp.seek(0)\n",
    "            self._predict(fp.name, self.data_yaml, self.img_size, self.project)\n",
    "\n",
    "        preds = {}\n",
    "        for label in os.listdir(os.path.join(self.project, 'labels')):\n",
    "            path_to_label = os.path.join(self.project, 'labels', label)\n",
    "            \n",
    "            with open(path_to_label, 'r') as f:\n",
    "                _, img_name = path_to_label.rsplit('/', maxsplit=1)\n",
    "                img_name = removesuffix(img_name, ['.txt']) + '.jpg'\n",
    "                preds[img_name] = [self.dct_preds(line) for line in f]\n",
    "                # preds[label.replace('txt', 'jpg')] = [self.dct_preds(i) for i in f.readlines()]\n",
    "                \n",
    "        return preds\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo = YoloWrapper(weights='best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 ðŸš€ v7.0-90-ga895e98 Python-3.8.5 torch-1.13.1 CPU\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "Model summary: 157 layers, 7012822 parameters, 0 gradients\n",
      "image 1/5 /Users/azatsultanov/Programming/vallib/repo/vallib/examples/yolo_test/data/test/images/image_1450_jpg.rf.e7ae062245bb8676d04fb109b2dd13b3.jpg: 256x256 1 vin, 856.2ms\n",
      "image 2/5 /Users/azatsultanov/Programming/vallib/repo/vallib/examples/yolo_test/data/test/images/image_1494_jpg.rf.265a51023951f36169386ec7383d8b6b.jpg: 256x256 2 vins, 116.1ms\n",
      "image 3/5 /Users/azatsultanov/Programming/vallib/repo/vallib/examples/yolo_test/data/test/images/image_1518_jpg.rf.07a3426d9ec6da2840d4af1bef33fb30.jpg: 256x256 1 vin, 100.1ms\n",
      "image 4/5 /Users/azatsultanov/Programming/vallib/repo/vallib/examples/yolo_test/data/test/images/image_1626_jpg.rf.088d36226e07b8127851a1bb1b79e0a6.jpg: 256x256 1 vin, 121.4ms\n",
      "image 5/5 /Users/azatsultanov/Programming/vallib/repo/vallib/examples/yolo_test/data/test/images/image_1720_jpg.rf.3471aa233437e81963497794f33fd312.jpg: 256x256 2 vins, 132.9ms\n",
      "Speed: 1.1ms pre-process, 265.3ms inference, 3.3ms NMS per image at shape (1, 3, 256, 256)\n",
      "Results saved to \u001b[1mpreds\u001b[0m\n",
      "5 labels saved to preds/labels\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "test_path = pathlib.Path('./data/test/images')\n",
    "samples = [str((test_path / file).resolve()) for file in os.listdir(test_path)[:5]]\n",
    "preds = yolo.predict(samples)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/azatsultanov/Programming/vallib/repo/vallib/examples/yolo_test/data'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_full_path(path):\n",
    "    return str(pathlib.Path(path).resolve())\n",
    "\n",
    "get_full_path('./data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'class_id': '0',\n",
       "  'center_x': 0.4609375,\n",
       "  'center_y': 0.498046875,\n",
       "  'width': 0.787109375,\n",
       "  'height': 0.087890625}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_labels_for_img(img_path):\n",
    "    prefix, _, file = img_path.rsplit('/', maxsplit=2)\n",
    "    file_txt = removesuffix(file, ['.jpg', '.jpeg']) + '.txt'\n",
    "    label_path = pathlib.Path(prefix) / 'labels' / file_txt\n",
    "\n",
    "    with open(label_path, 'r') as f:\n",
    "        labels = [YoloWrapper.dct_preds(line) for line in f]\n",
    "    return labels\n",
    "\n",
    "get_labels_for_img('./data/train/labels/rn707hrGaji74SaG1mSRqiZlsRYvZyqWyhFH9KF1_jpeg.rf.ffaae00a26a9dd2608dd54fde312b657.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def prepare_dataset(data_path):\n",
    "    res = {}\n",
    "    data_path = pathlib.Path(data_path)\n",
    "    res['X'] = [get_full_path(data_path/'images'/img_path) for img_path in os.listdir(data_path / 'images')]\n",
    "    res['y_true'] = [get_labels_for_img(img_path) for img_path in res['X']]\n",
    "    preds = yolo.predict(res['X'])\n",
    "\n",
    "    res['y_pred'] = []\n",
    "    for img_path in res['X']:\n",
    "        _, img_name = img_path.rsplit('/', maxsplit=1)\n",
    "        res['y_pred'].append(preds.get(img_name, [])) # maybe data was shuffled\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = prepare_dataset('./data/train/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oos = prepare_dataset('./data/test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle \n",
    "\n",
    "# with open('./train_dict.pkl', 'wb') as f:\n",
    "#     pickle.dump(train, f)\n",
    "\n",
    "# with open('./oos_dict.pkl', 'wb') as f:\n",
    "#     pickle.dump(oos, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "with open('./train_dict.pkl', 'rb') as f:\n",
    "    train = pickle.load(f)\n",
    "\n",
    "with open('./oos_dict.pkl', 'rb') as f:\n",
    "    oos = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'class_id': '0',\n",
       "   'center_x': 0.447266,\n",
       "   'center_y': 0.5,\n",
       "   'width': 0.785156,\n",
       "   'height': 0.09375,\n",
       "   'conf': 0.778243}],\n",
       " [{'class_id': '0',\n",
       "   'center_x': 0.605469,\n",
       "   'center_y': 0.548828,\n",
       "   'width': 0.460938,\n",
       "   'height': 0.113281,\n",
       "   'conf': 0.78405}]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sbe_vallib.sampler.supervised_sampler import SupervisedSampler\n",
    "\n",
    "sampler = SupervisedSampler(train, oos)\n",
    "sampler.set_state(seed=1, gen_method='bootstrap')\n",
    "sampler.train['y_pred'][:2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd external_libs/review_object_detection_metrics\n",
    "# pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sbe_vallib.scorer.base import BaseScorer\n",
    "from review_object_detection_metrics.bounding_box import BoundingBox, BBFormat, BBType, CoordinatesType\n",
    "from review_object_detection_metrics.evaluators.coco_evaluator import get_coco_summary\n",
    "\n",
    "class ObjDetScorerXCYCWH(BaseScorer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def calc_metrics(self, X, y_true, y_pred, model, **kwargs):\n",
    "        ground_truth = []\n",
    "        detected = []\n",
    "        for img_name, gt_boxes, det_boxes in zip(X, y_true, y_pred):\n",
    "            for gt_box in gt_boxes:\n",
    "                ground_truth.append(BoundingBox(\n",
    "                    image_name=img_name,\n",
    "                    class_id=gt_box['class_id'],\n",
    "                    coordinates=[gt_box[i] for i in ['center_x', 'center_y', 'width', 'height']],\n",
    "                    type_coordinates=CoordinatesType.RELATIVE,\n",
    "                    img_size=model.img_size,\n",
    "                    bb_type=BBType.GROUND_TRUTH,\n",
    "                    format=BBFormat.XYWH\n",
    "                ))\n",
    "            for det_box in det_boxes:\n",
    "                detected.append(BoundingBox(\n",
    "                    image_name=img_name,\n",
    "                    class_id=det_box['class_id'],\n",
    "                    coordinates=[det_box[i] for i in ['center_x', 'center_y', 'width', 'height']],\n",
    "                    type_coordinates=CoordinatesType.RELATIVE,\n",
    "                    img_size=model.img_size,\n",
    "                    confidence=det_box['conf'],\n",
    "                    bb_type=BBType.DETECTED,\n",
    "                    format=BBFormat.XYWH,\n",
    "                ))\n",
    "        return get_coco_summary(ground_truth, detected)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AP': 0.5089298121579297,\n",
       " 'AP50': 0.948672332920254,\n",
       " 'AP75': 0.4783974119706103,\n",
       " 'APsmall': 0.4769984293703652,\n",
       " 'APmedium': 0.5228687362370074,\n",
       " 'APlarge': 0.3833200020902735,\n",
       " 'AR1': 0.5885509838998211,\n",
       " 'AR10': 0.5930948121645796,\n",
       " 'AR100': 0.5930948121645796,\n",
       " 'ARsmall': 0.5671739130434783,\n",
       " 'ARmedium': 0.6001307759372276,\n",
       " 'ARlarge': 0.5133333333333333}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ObjDetScorerXCYCWH().calc_metrics(sampler.train['X'], sampler.train['y_true'], sampler.train['y_pred'], yolo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vallib_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4cc85873d42337b9e9e8da282a699b0819447065cfa6c32ea38d6a740a63d56"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
