{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sbe_vallib import Validation, BinaryScorer, BinarySampler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "X, y = make_classification(n_samples=1000, n_classes=2,\n",
    "                               n_features=5, n_informative=3, n_redundant=0,\n",
    "                               random_state=0)\n",
    "\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.Series(y)\n",
    "\n",
    "X_train, X_test,  y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression().fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampler Scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sbe_vallib import BinarySampler, BinaryScorer\n",
    "\n",
    "sampler = BinarySampler(train={'X': X_train, 'y_true': y_train, 'y_pred': model.predict_proba(X_train)},\n",
    "                        oos = {'X': X_test, 'y_true': y_test, 'y_pred': model.predict_proba(X_test)}, bootstrap=True)\n",
    "\n",
    "scorer = BinaryScorer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train_test_independence_test', 'test_extremal_missing_values', 'psi_factor_classes_test_oos', 'psi_factor_classes_test_oot', 'test_key_metric', 'test_confidence_inteval', 'test_presicion', 'test_recall', 'test_2_5', 'test_3_1', 'test_3_2', 'test_feature_importance', 'test_4_2', 'test_key_metric_stability', 'test_presicion_stability', 'test_recall_stability', 'test_5_4', 'test_5_6', 'test_5_7', 'test_0_0', 'test_0_0_1'])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def custom_test(model, scorer, sampler, a = 10, **kwargs):\n",
    "    metrics = []\n",
    "    for i in range(a):\n",
    "        sampler.set_seed(i)\n",
    "        train = sampler.train\n",
    "        oos = sampler.oos\n",
    "        model.fit(X=train[\"X\"], y=train[\"y_true\"])\n",
    "        y_pred = model.predict_proba(oos['X'])\n",
    "        metrics.append(scorer.score(oos['y_true'], y_pred))\n",
    "    \n",
    "    return {\n",
    "        \"semaphore\": \"grey\",\n",
    "        \"result_dict\": {'mean_f1': np.mean([i['f1_score'] for i in metrics])},\n",
    "        \"result_dataframes\": [pd.DataFrame(metrics)],\n",
    "        \"result_plots\": [],\n",
    "    }\n",
    "\n",
    "\n",
    "custom_tests = {\n",
    "    \"test_0_0\": {\"block\": \"model_stability\", \"callable\": custom_test, \"params\": {}},\n",
    "    \"test_0_0_1\": {\n",
    "        \"block\": \"model_stability\",\n",
    "        \"callable\": custom_test,\n",
    "        \"params\": {\"a\": 100},\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "validor = Validation(model, sampler, scorer, custom_tests=custom_tests,\n",
    "                         pipeline='../sbe_vallib/validation/table/pipelines/Config_31.xlsx')\n",
    "res = validor.validate()\n",
    "res.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>gini</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.726667</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.732394</td>\n",
       "      <td>0.717241</td>\n",
       "      <td>0.606347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.696667</td>\n",
       "      <td>0.710345</td>\n",
       "      <td>0.677632</td>\n",
       "      <td>0.693603</td>\n",
       "      <td>0.633890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.763333</td>\n",
       "      <td>0.726619</td>\n",
       "      <td>0.753731</td>\n",
       "      <td>0.739927</td>\n",
       "      <td>0.703830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.765101</td>\n",
       "      <td>0.770270</td>\n",
       "      <td>0.767677</td>\n",
       "      <td>0.691679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.699301</td>\n",
       "      <td>0.671141</td>\n",
       "      <td>0.684932</td>\n",
       "      <td>0.558025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.730000</td>\n",
       "      <td>0.775148</td>\n",
       "      <td>0.752874</td>\n",
       "      <td>0.763848</td>\n",
       "      <td>0.635742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.681159</td>\n",
       "      <td>0.701493</td>\n",
       "      <td>0.691176</td>\n",
       "      <td>0.625787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.725926</td>\n",
       "      <td>0.675862</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.620645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.753333</td>\n",
       "      <td>0.770370</td>\n",
       "      <td>0.707483</td>\n",
       "      <td>0.737589</td>\n",
       "      <td>0.662265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.703333</td>\n",
       "      <td>0.743056</td>\n",
       "      <td>0.672956</td>\n",
       "      <td>0.706271</td>\n",
       "      <td>0.549043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy_score  precision_score  recall_score  f1_score      gini\n",
       "0         0.726667         0.702703      0.732394  0.717241  0.606347\n",
       "1         0.696667         0.710345      0.677632  0.693603  0.633890\n",
       "2         0.763333         0.726619      0.753731  0.739927  0.703830\n",
       "3         0.770000         0.765101      0.770270  0.767677  0.691679\n",
       "4         0.693333         0.699301      0.671141  0.684932  0.558025\n",
       "..             ...              ...           ...       ...       ...\n",
       "95        0.730000         0.775148      0.752874  0.763848  0.635742\n",
       "96        0.720000         0.681159      0.701493  0.691176  0.625787\n",
       "97        0.720000         0.725926      0.675862  0.700000  0.620645\n",
       "98        0.753333         0.770370      0.707483  0.737589  0.662265\n",
       "99        0.703333         0.743056      0.672956  0.706271  0.549043\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['test_0_0_1']['result_dataframes'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vallib_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4cc85873d42337b9e9e8da282a699b0819447065cfa6c32ea38d6a740a63d56"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
