{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка инструментов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импорт необходимых инструментов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим перцептрон со случаными весами для имитации сложной функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "relu = np.vectorize(lambda x: x if x>0 else 0.)\n",
    "sigm = lambda x: 1./(1+np.exp(-x))\n",
    "\n",
    "vec_sizes = [45, 45, 45, 20, 15, 1]\n",
    "\n",
    "def perceptron(xx, vec_sizes):\n",
    "    \n",
    "    xx_ext = xx\n",
    "    generator = np.random.RandomState(43)\n",
    "    \n",
    "    for i, new_size in enumerate(vec_sizes):\n",
    "        xx_ext = np.hstack([np.ones((xx_ext.shape[0], 1)), xx_ext])\n",
    "        \n",
    "        weights = generator.normal(0., 1, size=(xx_ext.shape[1], new_size))\n",
    "        \n",
    "        xx_ext = relu(xx_ext.dot(weights))\n",
    "        \n",
    "    return np.floor(xx_ext.reshape((-1,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Генерация данных, построение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сгенерируем нормально распределенные фичи и с помощью случайного \n",
    "перцептрона сымитируем зависимость целевой переменной. Сгенерированный \n",
    "датафрейм состоит из признаков, которые вошли в итоговую модель.\n",
    "\n",
    "Предположим, что факторы feat_3, feat_8, feat_13, feat_27\n",
    "являются защищенными характеристиками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-08T14:04:20.992857Z",
     "start_time": "2022-08-08T14:04:12.243711Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Генератор \n",
    "gen = np.random.RandomState(42)\n",
    "\n",
    "\n",
    "# Генерация признаков\n",
    "X = pd.DataFrame(data=gen.normal(50., 100., size=(30000, 30)),\n",
    "                 columns=[f'feat_{i}' for i in range(30)],\n",
    "                 index=[i for i in range(30000)])\n",
    "\n",
    "\n",
    "# Имитация зависимости\n",
    "y = pd.Series(data=1*(perceptron(X.values, [60, 32, 12, 5, 1])>0),\n",
    "              index=[i for i in range(30000)],\n",
    "              name='target'\n",
    "             )\n",
    "\n",
    "# Защищенные характеристики \n",
    "fair_factors = ['feat_3', 'feat_8', 'feat_13', 'feat_27']\n",
    "\n",
    "# Остальные признаки\n",
    "no_fair_factors = list(set(X.columns) - set(fair_factors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сгенеруем защищенные характеристики и \"руками\" внесем дискриминацию.\n",
    "С помощью другого случайного перцептрона сымитируем зависимость \n",
    "одного защищенного фактора от признаков, не являющихся защищенными характеристиками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/th/9030k3h14s3ffm4831c1n0mm0000gn/T/ipykernel_659/739543630.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['feat_3'][y>0]=gen.randint(30, 41, size=(len(X['feat_3'][y>0]),))\n",
      "/var/folders/th/9030k3h14s3ffm4831c1n0mm0000gn/T/ipykernel_659/739543630.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['feat_8'][y>0]=gen.choice([0, 1], size=(len(X['feat_8'][y>0]),), p=[0.1, 0.9])\n"
     ]
    }
   ],
   "source": [
    "# Генерация\n",
    "X['feat_3'] = gen.randint(18, 40, size=(30000,))\n",
    "\n",
    "# Внесение \"руками\" дискриминации\n",
    "X['feat_3'][y>0]=gen.randint(30, 41, size=(len(X['feat_3'][y>0]),))\n",
    "\n",
    "# Генерация\n",
    "X['feat_8'] = gen.choice([0, 1], size=(30000,), p=[0.4, 0.6])\n",
    "\n",
    "# Внесение \"руками\" дискриминации\n",
    "X['feat_8'][y>0]=gen.choice([0, 1], size=(len(X['feat_8'][y>0]),), p=[0.1, 0.9])\n",
    "\n",
    "# Генерация\n",
    "X['feat_13'] = gen.uniform(0, 10, size=(30000,))\n",
    "\n",
    "# Имитация зависимости \n",
    "X['feat_27'] = perceptron(X[no_fair_factors].values, vec_sizes)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разобьем данные и закинем их в sampler, также создадим scorer(он необходим для любой валидации, но имеено в тестах по fairness он не используется, поэтому выберем самый обычный)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sbe_vallib.sampler.supervised_sampler import SupervisedSampler\n",
    "from sbe_vallib.scorer.table_scorer import BinaryScorer\n",
    "\n",
    "X_train, X_oos, y_train, y_oos = train_test_split(X, y, \n",
    "                                                  test_size=0.1, \n",
    "                                                  random_state=42,\n",
    "                                                  stratify=y)\n",
    "sampler = SupervisedSampler(train={'X': X_train, 'y_true': y_train}, oos={'X': X_oos, 'y_true': y_oos})\n",
    "scorer = BinaryScorer()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим итоговую модель, она должны быть в sklearn-like формате, то есть реализовать методы predict_proba, fit, predict И АТРИБУТ classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.928486405179499"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(sampler.train['X'], sampler.train['y_true'])\n",
    "roc_auc_score(sampler.oos['y_true'], model.predict_proba(sampler.oos['X'])[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Пайплайн fairness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим object validation и передадим в него конфиг для fairness анализа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sbe_vallib.validation import Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Первый способ, это передать, просто путь до конфига, но тогда придется, для каждого теста прописать значения для параметра protected_feats\n",
    "# Не думаю, что это удобно\n",
    "val = Validation(model=model,\n",
    "                 sampler=sampler,\n",
    "                 scorer=scorer,\n",
    "                 pipeline='../src/sbe_vallib/table/pipelines/fairness_config.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conf_lvl': 0.95,\n",
       " 'n_bootstrap': 200,\n",
       " 'random_seed': 1,\n",
       " 'protected_feats': ['feat_3', 'feat_8', 'feat_13', 'feat_27']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# второй способ это считать config.xlxs из файла и затем дополнить получившийся json тем, что нам надо\n",
    "\n",
    "val = Validation(model=model,\n",
    "                 sampler=sampler,\n",
    "                 scorer=scorer,\n",
    "                 pipeline='../src/sbe_vallib/table/pipelines/fairness_config.xlsx')\n",
    "\n",
    "for test_key in val.pipeline['tests_desc']:\n",
    "    val.pipeline['tests_desc'][test_key]['params'].update({'protected_feats': fair_factors})\n",
    "val.pipeline['tests_desc']['test_indirect_discr']['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fair_facotrs: ['feat_3', 'feat_8', 'feat_13', 'feat_27']\n"
     ]
    }
   ],
   "source": [
    "#третий наиболее удобный это воспользоваться агрументом валидации tests_params. этот словарь будет передаваться в каждый тест с наивысшим приоритетом.\n",
    "# перед этим конфиг считается, поэтому абсолютно все параметры передавать не надо.\n",
    "\n",
    "val = Validation(model=model,\n",
    "                 sampler=sampler,\n",
    "                 scorer=scorer,\n",
    "                 pipeline='../src/sbe_vallib/table/pipelines/fairness_config.xlsx',\n",
    "                 tests_params={'protected_feats': fair_factors, 'min_freq_pos': 0.00, 'min_freq_value': 0.03, 'cat_features': None},\n",
    "                 exclude_tests=[],\n",
    "                 store_path='./fairness_results')\n",
    "print(f'fair_facotrs: {fair_factors}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isna(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/azatsultanov/Programming/vallib/repo/vallib/src/sbe_vallib/table/fairness/test_tprd_fprd_delta.py:129: RuntimeWarning: Mean of empty slice.\n",
      "  groups_metric['fpr'].append(source_preds[target == 0].mean())\n",
      "/Users/azatsultanov/Programming/vallib/vallib_env/lib/python3.8/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/azatsultanov/Programming/vallib/repo/vallib/src/sbe_vallib/table/fairness/test_tprd_fprd_delta.py:133: RuntimeWarning: Mean of empty slice.\n",
      "  swap_preds[target == 0].mean())\n"
     ]
    }
   ],
   "source": [
    "#Возможны warning по поводу, взятия среднего по пустому списку - это нормально, просто при подсчете TPR FPR, получилось так, что есть только один класс\n",
    "res = val.validate(save_excel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Итак у нас получились следующие тесты\n",
    "res.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res['test_indirect_discr']['result_dataframes'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res['test_target_rate_delta']['result_dataframes'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res['test_tprd_fprd_delta']['result_dataframes'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res['test_oppr_priv_ci']['result_dataframes'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Пайплайн fairness для реальных данных "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У вас должны быть:\n",
    "1) выборки train и OOS\n",
    "2) используемые признаки - здесь я взял их из модели разработчика\n",
    "3) обученная вами модель valid_model с методом predict_proba\n",
    "4) категориальные признаки - если не уверены, оставляйте в вызове метода FairnessValidation cat_features=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fair_factors = ['sd_gender_cd',\n",
    "'sd_age_yrs_frac_nv',\n",
    "'sd_age_yrs_comp_nv',\n",
    "'sd_client_valid_nflag',\n",
    "'sd_stlmnt_type_cd',\n",
    "'sd_russian_citizen_nflag',\n",
    "'sd_resident_nflag',\n",
    "'sd_sbrf_employee_nflag',\n",
    "'dep_social_client_nflag',\n",
    "'lne_coborrower_nflag',\n",
    "'lne_loan_overdue_nflag',\n",
    "'prl_employee_dzo_nflag',\n",
    "'prl_social_disab_pension_nflag',\n",
    "'seg_client_mp_segment_cd',\n",
    "'seg_crd_pos_cat_group',\n",
    "'seg_crd_trx_segm',\n",
    "'seg_crd_trx_subsegm',\n",
    "'seg_age_segment',\n",
    "'sd_name_age_segment_cd',\n",
    "'sd_age_mnth_comp_nv',\n",
    "'sd_cb_staff_nflag',\n",
    "'client_region']\n",
    "feats_for_analyse = list(set(model.used_features) & set(fair_factors))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "5706a67963694452c319b60dc31d857a4746ad2127af76ef31bb2e4886d1178d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
