{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset conll2003 (/Users/kirillsergeev/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98)\n",
      "100%|██████████| 3/3 [00:00<00:00, 484.26it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33e6d98f7baa43a3ad37ab83fcd5634f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': '2',\n",
       " 'tokens': ['AL-AIN', ',', 'United', 'Arab', 'Emirates', '1996-12-06'],\n",
       " 'pos_tags': [22, 6, 22, 22, 23, 11],\n",
       " 'chunk_tags': [11, 0, 11, 12, 12, 12],\n",
       " 'ner_tags': [5, 0, 5, 6, 6, 0]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datasets\n",
    "conll = datasets.load_dataset(\"conll2003\")\n",
    "CONLL_NER_TAGS = conll['train'].features['ner_tags'].feature.names\n",
    "print(CONLL_NER_TAGS)\n",
    "conll[\"test\"][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (pipeline, \n",
    "        AutoModelForTokenClassification, AutoTokenizer, \n",
    "        BertForTokenClassification, BertTokenizer)\n",
    "\n",
    "# Load pretrained model and tokenizer for English NER task (dslim/bert-base-NER)\n",
    "model_name = \"dslim/bert-base-NER\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = BertForTokenClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "class ModelWrapper():\n",
    "    def __init__(self, model, tokenizer):\n",
    "        self.model = pipeline('ner', model=model, tokenizer=tokenizer, aggregation_strategy=None)\n",
    "\n",
    "    def _unite_entities(self, entities):\n",
    "        if len(entities) <= 1:\n",
    "            return entities\n",
    "\n",
    "        united_result = []\n",
    "        cur_entity = {key: entities[0][key] for key in ['entity', 'word', 'start', 'end']}\n",
    "        for entity in entities[1:]:\n",
    "            if entity['word'].startswith('##'):\n",
    "                cur_entity['word'] += entity['word'].lstrip('#')\n",
    "                cur_entity['end'] = entity['end']\n",
    "            else:\n",
    "                united_result.append(cur_entity)\n",
    "                cur_entity = {key: entity[key] for key in ['entity', 'word', 'start', 'end']}\n",
    "        united_result.append(cur_entity)\n",
    "        return united_result\n",
    "\n",
    "    def _convert_entities_to_bio(self, tokens, entities):\n",
    "        bio_tags = []\n",
    "        cur_entity_idx = 0\n",
    "        for token in tokens:\n",
    "            if (cur_entity_idx < len(entities))\\\n",
    "                    and (token == entities[cur_entity_idx]['word']):\n",
    "                bio_tags.append(entities[cur_entity_idx]['entity'])\n",
    "                cur_entity_idx += 1\n",
    "            else:\n",
    "                bio_tags.append('O')\n",
    "        return bio_tags\n",
    "\n",
    "    def _postprocessing(self, tokens, model_output):\n",
    "        entities = self._unite_entities(model_output)\n",
    "        bio_tags = self._convert_entities_to_bio(tokens, entities)\n",
    "        return bio_tags\n",
    "\n",
    "    def predict(self, X):\n",
    "        with torch.no_grad():\n",
    "            ner_entitites = self.model(X)\n",
    "            tags = []\n",
    "            for text, entities in tqdm(zip(X, ner_entitites)):\n",
    "                tags.append(self._postprocessing(text.split(), entities))\n",
    "            return tags\n",
    "\n",
    "wrapped_model = ModelWrapper(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_dataset(dataset):\n",
    "    result = {'X': [], 'y_true': []}\n",
    "    for sample in dataset:\n",
    "        result['X'].append(' '.join(sample['tokens']))\n",
    "        result['y_true'].append([CONLL_NER_TAGS[tag] for tag in sample['ner_tags']])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from itertools import islice\n",
    "# train_data = preprocessing_dataset(conll['train'])\n",
    "# train_data['y_pred'] = wrapped_model.predict(train_data['X'])\n",
    "\n",
    "# oos_data = preprocessing_dataset(conll['test'])\n",
    "# oos_data['y_pred'] = wrapped_model.predict(oos_data['X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# with open('./train_data.pkl', 'wb') as f:\n",
    "#     pickle.dump(train_data, f)\n",
    "# with open('./oos_data.pkl', 'wb') as f:\n",
    "#     pickle.dump(oos_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./train_data.pkl', 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "\n",
    "with open('./oos_data.pkl', 'rb') as f:\n",
    "    oos_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(all([len(i) == len(j) for i, j in zip(train_data['y_true'], train_data['y_pred'])]))\n",
    "print(all([len(i) == len(j) for i, j in zip(oos_data['y_true'], oos_data['y_pred'])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sbe_vallib.validation.sampler.ner_sampler import NerSampler\n",
    "\n",
    "sampler = NerSampler(train=train_data, oos=oos_data)\n",
    "sampler.set_seed(42, bootstrap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LOC', 'MISC', 'ORG', 'PER']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(set([tag.split('-')[-1] for tag in CONLL_NER_TAGS]) - set(['O'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision_score': {'LOC': 0.9363057324840764,\n",
       "  'MISC': 0.804920913884007,\n",
       "  'ORG': 0.8944262295081967,\n",
       "  'PER': 0.9319965126416739,\n",
       "  'micro avg': 0.9043806982432733,\n",
       "  'macro avg': 0.8919123471294885,\n",
       "  'weighted avg': 0.9064257739880867},\n",
       " 'f1_score': {'LOC': 0.8043775649794801,\n",
       "  'MISC': 0.7206923682140047,\n",
       "  'ORG': 0.8562460765850596,\n",
       "  'PER': 0.7735166425470332,\n",
       "  'micro avg': 0.8017742730409069,\n",
       "  'macro avg': 0.7887081630813945,\n",
       "  'weighted avg': 0.800394646791491},\n",
       " 'recall_score': {'LOC': 0.7050359712230215,\n",
       "  'MISC': 0.6524216524216524,\n",
       "  'ORG': 0.8211920529801324,\n",
       "  'PER': 0.6611008039579468,\n",
       "  'micro avg': 0.7200779036827195,\n",
       "  'macro avg': 0.7099376201456882,\n",
       "  'weighted avg': 0.7200779036827195},\n",
       " 'support': {'LOC': 1668,\n",
       "  'MISC': 702,\n",
       "  'ORG': 1661,\n",
       "  'PER': 1617,\n",
       "  'micro avg': 5648,\n",
       "  'macro avg': 5648,\n",
       "  'weighted avg': 5648}}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sbe_vallib.validation.scorer.ner_scorer import NerScorer\n",
    "from sbe_vallib.validation.utils.metrics import NER_IOB_METRICS\n",
    "\n",
    "\n",
    "scorer = NerScorer(metrics=NER_IOB_METRICS, )\n",
    "scores = scorer.score(oos_data['y_true'], oos_data['y_pred'])\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'f1_ent_type': {'LOC': 0.8062648961525366,\n",
       "              'MISC': 0.7612179487179488,\n",
       "              'ORG': 0.8829452485840151,\n",
       "              'PER': 0.8030194104960461,\n",
       "              'macro': 0.8238541153277475},\n",
       "             'f1_partial': {'LOC': 0.8478038815117467,\n",
       "              'MISC': 0.7908653846153845,\n",
       "              'ORG': 0.9118942731277533,\n",
       "              'PER': 0.8076923076923076,\n",
       "              'macro': 0.8498767865943814},\n",
       "             'f1_strict': {'LOC': 0.800817160367722,\n",
       "              'MISC': 0.733974358974359,\n",
       "              'ORG': 0.8584015103838892,\n",
       "              'PER': 0.7685118619698059,\n",
       "              'macro': 0.8017742730409069},\n",
       "             'f1_exact': {'LOC': 0.8409942117807286,\n",
       "              'MISC': 0.767628205128205,\n",
       "              'ORG': 0.8923851478917558,\n",
       "              'PER': 0.7886412652767792,\n",
       "              'macro': 0.8337111877772303}})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scorer.ner_metrics(oos_data['y_true'], oos_data['y_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sbe_vallib.validation.nlp.general_tests.model_quality.test_key_metric import test_key_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>support</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>semaphore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PER</td>\n",
       "      <td>1617</td>\n",
       "      <td>0.773517</td>\n",
       "      <td>green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MISC</td>\n",
       "      <td>702</td>\n",
       "      <td>0.720692</td>\n",
       "      <td>green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LOC</td>\n",
       "      <td>1668</td>\n",
       "      <td>0.804378</td>\n",
       "      <td>green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ORG</td>\n",
       "      <td>1661</td>\n",
       "      <td>0.856246</td>\n",
       "      <td>green</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tag  support  f1-score semaphore\n",
       "0   PER     1617  0.773517     green\n",
       "1  MISC      702  0.720692     green\n",
       "2   LOC     1668  0.804378     green\n",
       "3   ORG     1661  0.856246     green"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_key_metric(wrapped_model, scorer, sampler)['result_dataframes'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import classification_report\n",
    "\n",
    "res = classification_report(oos_data['y_true'], oos_data['y_pred'], output_dict=True)\n",
    "\n",
    "def _ner_recall(y_true, y_pred):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nervaluate import Evaluator\n",
    "\n",
    "evaluator = Evaluator(oos_data['y_true'], oos_data['y_pred'], tags=['PER', 'MISC', 'LOC', 'ORG'], loader='list')\n",
    "ner_metrics, ner_metrics_by_tag = evaluator.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'f1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m np\u001b[39m.\u001b[39mmean([ner_metrics_by_tag[i][\u001b[39m'\u001b[39m\u001b[39mf1\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m ner_metrics_by_tag])\n",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m np\u001b[39m.\u001b[39mmean([ner_metrics_by_tag[i][\u001b[39m'\u001b[39;49m\u001b[39mf1\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m ner_metrics_by_tag])\n",
      "\u001b[0;31mKeyError\u001b[0m: 'f1'"
     ]
    }
   ],
   "source": [
    "np.mean([ner_metrics_by_tag[i]['f1'] for i in ner_metrics_by_tag])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PER', 'MISC', 'LOC', 'ORG']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ner_metrics_by_tag.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of sbe_vallib.validation.scorer.ner_scorer failed: Traceback (most recent call last):\n",
      "  File \"/Users/azatsultanov/Programming/vallib/vallib_env/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 261, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/Users/azatsultanov/Programming/vallib/vallib_env/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 459, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/Users/azatsultanov/miniconda/lib/python3.8/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 604, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 779, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 916, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 846, in source_to_code\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/Users/azatsultanov/Programming/vallib/repo/vallib/sbe_vallib/validation/scorer/ner_scorer.py\", line 29\n",
      "    for schema in ['ent_type', 'partial', 'strict', 'exact']:\n",
      "    ^\n",
      "IndentationError: expected an indented block\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'PER': {'ent_type': {'correct': 1117,\n",
       "   'incorrect': 33,\n",
       "   'partial': 0,\n",
       "   'missed': 467,\n",
       "   'spurious': 15,\n",
       "   'possible': 1617,\n",
       "   'actual': 1165,\n",
       "   'precision': 0.9587982832618026,\n",
       "   'recall': 0.6907854050711194,\n",
       "   'f1': 0.8030194104960461},\n",
       "  'partial': {'correct': 1097,\n",
       "   'incorrect': 0,\n",
       "   'partial': 53,\n",
       "   'missed': 467,\n",
       "   'spurious': 15,\n",
       "   'possible': 1617,\n",
       "   'actual': 1165,\n",
       "   'precision': 0.9643776824034335,\n",
       "   'recall': 0.6948051948051948,\n",
       "   'f1': 0.8076923076923076},\n",
       "  'strict': {'correct': 1069,\n",
       "   'incorrect': 81,\n",
       "   'partial': 0,\n",
       "   'missed': 467,\n",
       "   'spurious': 15,\n",
       "   'possible': 1617,\n",
       "   'actual': 1165,\n",
       "   'precision': 0.9175965665236051,\n",
       "   'recall': 0.6611008039579468,\n",
       "   'f1': 0.7685118619698059},\n",
       "  'exact': {'correct': 1097,\n",
       "   'incorrect': 53,\n",
       "   'partial': 0,\n",
       "   'missed': 467,\n",
       "   'spurious': 15,\n",
       "   'possible': 1617,\n",
       "   'actual': 1165,\n",
       "   'precision': 0.9416309012875537,\n",
       "   'recall': 0.6784168212739641,\n",
       "   'f1': 0.7886412652767792}},\n",
       " 'MISC': {'ent_type': {'correct': 475,\n",
       "   'incorrect': 33,\n",
       "   'partial': 0,\n",
       "   'missed': 194,\n",
       "   'spurious': 38,\n",
       "   'possible': 702,\n",
       "   'actual': 546,\n",
       "   'precision': 0.86996336996337,\n",
       "   'recall': 0.6766381766381766,\n",
       "   'f1': 0.7612179487179488},\n",
       "  'partial': {'correct': 479,\n",
       "   'incorrect': 0,\n",
       "   'partial': 29,\n",
       "   'missed': 194,\n",
       "   'spurious': 38,\n",
       "   'possible': 702,\n",
       "   'actual': 546,\n",
       "   'precision': 0.9038461538461539,\n",
       "   'recall': 0.7029914529914529,\n",
       "   'f1': 0.7908653846153845},\n",
       "  'strict': {'correct': 458,\n",
       "   'incorrect': 50,\n",
       "   'partial': 0,\n",
       "   'missed': 194,\n",
       "   'spurious': 38,\n",
       "   'possible': 702,\n",
       "   'actual': 546,\n",
       "   'precision': 0.8388278388278388,\n",
       "   'recall': 0.6524216524216524,\n",
       "   'f1': 0.733974358974359},\n",
       "  'exact': {'correct': 479,\n",
       "   'incorrect': 29,\n",
       "   'partial': 0,\n",
       "   'missed': 194,\n",
       "   'spurious': 38,\n",
       "   'possible': 702,\n",
       "   'actual': 546,\n",
       "   'precision': 0.8772893772893773,\n",
       "   'recall': 0.6823361823361823,\n",
       "   'f1': 0.767628205128205}},\n",
       " 'LOC': {'ent_type': {'correct': 1184,\n",
       "   'incorrect': 71,\n",
       "   'partial': 0,\n",
       "   'missed': 413,\n",
       "   'spurious': 14,\n",
       "   'possible': 1668,\n",
       "   'actual': 1269,\n",
       "   'precision': 0.9330181245074862,\n",
       "   'recall': 0.709832134292566,\n",
       "   'f1': 0.8062648961525366},\n",
       "  'partial': {'correct': 1235,\n",
       "   'incorrect': 0,\n",
       "   'partial': 20,\n",
       "   'missed': 413,\n",
       "   'spurious': 14,\n",
       "   'possible': 1668,\n",
       "   'actual': 1269,\n",
       "   'precision': 0.9810874704491725,\n",
       "   'recall': 0.7464028776978417,\n",
       "   'f1': 0.8478038815117467},\n",
       "  'strict': {'correct': 1176,\n",
       "   'incorrect': 79,\n",
       "   'partial': 0,\n",
       "   'missed': 413,\n",
       "   'spurious': 14,\n",
       "   'possible': 1668,\n",
       "   'actual': 1269,\n",
       "   'precision': 0.9267139479905437,\n",
       "   'recall': 0.7050359712230215,\n",
       "   'f1': 0.800817160367722},\n",
       "  'exact': {'correct': 1235,\n",
       "   'incorrect': 20,\n",
       "   'partial': 0,\n",
       "   'missed': 413,\n",
       "   'spurious': 14,\n",
       "   'possible': 1668,\n",
       "   'actual': 1269,\n",
       "   'precision': 0.9732072498029944,\n",
       "   'recall': 0.7404076738609112,\n",
       "   'f1': 0.8409942117807286}},\n",
       " 'ORG': {'ent_type': {'correct': 1403,\n",
       "   'incorrect': 77,\n",
       "   'partial': 0,\n",
       "   'missed': 181,\n",
       "   'spurious': 37,\n",
       "   'possible': 1661,\n",
       "   'actual': 1517,\n",
       "   'precision': 0.924851680949242,\n",
       "   'recall': 0.8446718844069837,\n",
       "   'f1': 0.8829452485840151},\n",
       "  'partial': {'correct': 1418,\n",
       "   'incorrect': 0,\n",
       "   'partial': 62,\n",
       "   'missed': 181,\n",
       "   'spurious': 37,\n",
       "   'possible': 1661,\n",
       "   'actual': 1517,\n",
       "   'precision': 0.9551746868820039,\n",
       "   'recall': 0.872366044551475,\n",
       "   'f1': 0.9118942731277533},\n",
       "  'strict': {'correct': 1364,\n",
       "   'incorrect': 116,\n",
       "   'partial': 0,\n",
       "   'missed': 181,\n",
       "   'spurious': 37,\n",
       "   'possible': 1661,\n",
       "   'actual': 1517,\n",
       "   'precision': 0.8991430454845089,\n",
       "   'recall': 0.8211920529801324,\n",
       "   'f1': 0.8584015103838892},\n",
       "  'exact': {'correct': 1418,\n",
       "   'incorrect': 62,\n",
       "   'partial': 0,\n",
       "   'missed': 181,\n",
       "   'spurious': 37,\n",
       "   'possible': 1661,\n",
       "   'actual': 1517,\n",
       "   'precision': 0.934739617666447,\n",
       "   'recall': 0.8537025888019265,\n",
       "   'f1': 0.8923851478917558}}}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_metrics_by_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ea1ba28ca3080e0412ec99e1bb1a997d4a43b70d799a956f8141a171308cbcce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
